{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip Install Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from shapely.prepared import prep\n",
    "from shapely.geometry import mapping, shape, Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Const Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_COLUMN_NAME = \"year\"\n",
    "DECADE_COLUMN_NAME = \"decade\"\n",
    "SONG_TITLE_COLUMN_NAME = \"song_title\"\n",
    "COUNTRY_COLUMN_NAME = \"country\"\n",
    "ARTIST_LONGITUDE_COLUMN_NAME = \"artist_longitude\"\n",
    "ARTIST_LATITUDE_COLUMN_NAME = \"artist_latitude\"\n",
    "ARTIST_LOCATION_COLUMN_NAME = \"artist_location\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Songs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_songs_dataset = pd.read_csv(\"../Data/songs_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_songs_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_songs_dataset.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: For now I am going to delete all rows with missing data.<br>\n",
    "This is an initial approach, let's discuss it together with Elisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_dataset = raw_songs_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(songs_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Adding year column to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_dataset = songs_dataset.assign(decade=lambda row: (row[YEAR_COLUMN_NAME].astype(int) // 10) * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_decade = songs_dataset[DECADE_COLUMN_NAME].min()\n",
    "max_decade = songs_dataset[DECADE_COLUMN_NAME].max()\n",
    "\n",
    "decade_array = np.linspace(min_decade, max_decade, 10, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najeeb: Introducing a new column \"country\" based on Latitude and Longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and process the geojson data from a local file\n",
    "with open(r'..\\Data\\countries.geojson.json', 'r') as file:\n",
    "    geojson_data = json.load(file)\n",
    "\n",
    "countries = {}\n",
    "for feature in geojson_data[\"features\"]:\n",
    "    geom = feature[\"geometry\"]\n",
    "    country = feature[\"properties\"][\"ADMIN\"]\n",
    "    countries[country] = prep(shape(geom))\n",
    "\n",
    "# Function to get country name from latitude and longitude\n",
    "def get_country(lon, lat):\n",
    "    point = Point(lon, lat)\n",
    "    for country, geom in countries.items():\n",
    "        if geom.contains(point):\n",
    "            return country\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "# Apply the function to create a new 'country' column\n",
    "songs_dataset[COUNTRY_COLUMN_NAME] = songs_dataset.apply(\n",
    "    lambda row: get_country(row[ARTIST_LONGITUDE_COLUMN_NAME], \n",
    "    row[ARTIST_LATITUDE_COLUMN_NAME]), \n",
    "    axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Deleting redundant columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_dataset = songs_dataset.drop(\n",
    "    [\n",
    "        ARTIST_LATITUDE_COLUMN_NAME,\n",
    "        ARTIST_LONGITUDE_COLUMN_NAME,\n",
    "        ARTIST_LOCATION_COLUMN_NAME\n",
    "    ], \n",
    "    axis=1)\n",
    "\n",
    "songs_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Now I am going to create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_graph = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_graph.add_nodes_from(decade_array.tolist())\n",
    "\n",
    "decade_graph.add_nodes_from(songs_dataset[SONG_TITLE_COLUMN_NAME].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = []\n",
    "for index, row in songs_dataset.iterrows():\n",
    "    current_song_title = row[SONG_TITLE_COLUMN_NAME]\n",
    "    current_decade = row[DECADE_COLUMN_NAME]\n",
    "\n",
    "    relationships.append((current_decade, current_song_title, {\"label\": \"release_decade\"}))\n",
    "\n",
    "decade_graph.add_edges_from(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decade_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_input = 1920\n",
    "\n",
    "songs_from_given_decade = [ song for song in decade_graph[decade_input].keys()]\n",
    "songs_from_given_decade"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a5cfde8991b0f64e8bcd60a397bea8dc10ed042aefe1441fd3daa2ae2091421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
