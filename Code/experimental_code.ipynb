{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip Install Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in w:\\program files\\python310\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy<2,>=1.14 in w:\\program files\\python310\\lib\\site-packages (from shapely) (1.26.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (w:\\program files\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (w:\\program files\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (w:\\program files\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (w:\\program files\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (w:\\program files\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (w:\\program files\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install shapely\n",
    "%pip install node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:33:28.414764Z",
     "start_time": "2024-05-19T01:33:28.408600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.prepared import prep\n",
    "from shapely.geometry import mapping, shape, Point\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Const Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:27:45.218121Z",
     "start_time": "2024-05-19T01:27:45.210909Z"
    }
   },
   "outputs": [],
   "source": [
    "YEAR_COLUMN = \"year\"\n",
    "TEMPO_COLUMN = \"tempo\"\n",
    "LOUDNESS_COLUMN = \"loudness\"\n",
    "DURATION_COLUMN = \"duration\"\n",
    "SONG_HOTTTNESSS_COLUMN = \"song_hotttnesss\"\n",
    "ARTIST_HOTTTNESSS_COLUMN = \"artist_hotttnesss\"\n",
    "ARTIST_FAMILIARITY_COLUMN = \"artist_familiarity\"\n",
    "DECADE_COLUMN = \"decade\"\n",
    "\n",
    "NUMERIC_COLUMNS_LIST = [\n",
    "    YEAR_COLUMN,\n",
    "    TEMPO_COLUMN,\n",
    "    LOUDNESS_COLUMN,\n",
    "    DURATION_COLUMN,\n",
    "    SONG_HOTTTNESSS_COLUMN,\n",
    "    ARTIST_HOTTTNESSS_COLUMN,\n",
    "    ARTIST_FAMILIARITY_COLUMN,\n",
    "    DECADE_COLUMN\n",
    "]\n",
    "\n",
    "SONG_TITLE_COLUMN = \"song_title\"\n",
    "COUNTRY_COLUMN = \"country\"\n",
    "ARTIST_LONGITUDE_COLUMN = \"artist_longitude\"\n",
    "ARTIST_LATITUDE_COLUMN = \"artist_latitude\"\n",
    "ARTIST_LOCATION_COLUMN = \"artist_location\"\n",
    "ARTIST_ID_COLUMN = \"artist_id\"\n",
    "SONG_ID_COLUMN = \"song_id\"\n",
    "\n",
    "UNKNOWN_COUNTRY_VALUE = \"unknown\"\n",
    "MUSIC_DATA_FOLDER_PATH = \"../Music Data/\"\n",
    "MODELS_FOLDER_PATH = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:27:50.576433Z",
     "start_time": "2024-05-19T01:27:50.568989Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attribute_node_name(node_type, node_value):\n",
    "    return f\"{node_type} {node_value}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Songs & Artists datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:27:57.190474Z",
     "start_time": "2024-05-19T01:27:53.037398Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_songs_dataset = pd.read_csv(\"../Data/songs_dataset.csv\")\n",
    "raw_artists_dataset = pd.read_csv(\"../Data/artist_terms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Riaz: Merging datasets based on artist_id<br>\n",
    "In the following cell i am removing the duplicate rows based on `artist_id` and only keep the first record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:02.377791Z",
     "start_time": "2024-05-19T01:28:01.484221Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicates from the artist dataset based on artist_id\n",
    "raw_artists_dataset = raw_artists_dataset.drop_duplicates(subset=ARTIST_ID_COLUMN, keep='first')\n",
    "\n",
    "# Merge the datasets on artist_id\n",
    "raw_music_dataset = pd.merge(raw_songs_dataset, raw_artists_dataset, on=ARTIST_ID_COLUMN, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the above cell i merged the datasets based on artist_id and merge was on left join:\n",
    "When you specify how='left', it means that all the keys from the left dataframe (in this case, the raw_songs_dataset dataframe) will be included in the merged dataframe, and only the matching keys from the right dataframe (in this case, the artist_dataset dataframe) will be added.\n",
    "\n",
    "In other words:\n",
    "\n",
    "All rows from the left dataframe (raw_songs_dataset) are retained.\n",
    "If there are matching keys (in this case, artist_id) in the right dataframe (artist_dataset), the corresponding data from the right dataframe will be added to the merged dataframe.\n",
    "If there are no matching keys in the right dataframe, the corresponding columns in the merged dataframe will be filled with NaN (missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:07.260445Z",
     "start_time": "2024-05-19T01:28:07.218709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              song_id                                         song_title  \\\n0  SOVFVAK12A8C1350D9                                        Tanssi vaan   \n1  SOGTUKN12AB017F4F1                                  No One Could Ever   \n2  SOBNYVR12A8C13558C                                      Si Vos Querés   \n3  SOHSBXH12A8C13B0DF                                   Tangle Of Aspens   \n4  SOZVAPQ12A8C13B63C  Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...   \n\n     year                               release    tempo  loudness   duration  \\\n0  1995.0                           Karkuteillä  150.778   -10.555  156.55138   \n1  2006.0                                Butter  177.768    -2.060  138.97098   \n2  2003.0                               De Culo   87.433    -4.654  145.05751   \n3     NaN  Rene Ablaze Presents Winter Sessions  140.035    -7.806  514.29832   \n4     NaN      Berwald: Symphonies Nos. 1/2/3/4   90.689   -21.420  816.53506   \n\n   song_hotttnesss           artist_id       artist_name  artist_latitude  \\\n0         0.299877  ARMVN3U1187FB3A1EB  Karkkiautomaatti              NaN   \n1         0.617871  ARGEKB01187FB50750    Hudson Mohawke          55.8578   \n2              NaN  ARNWYLR1187B9B2F9C       Yerba Brava              NaN   \n3              NaN  AREQDTE1269FB37231        Der Mystic              NaN   \n4              NaN  AR2NS5Y1187FB5879D  David Montgomery              NaN   \n\n   artist_longitude    artist_location  artist_hotttnesss  artist_familiarity  \\\n0               NaN                NaN           0.356992            0.439604   \n1          -4.24251  Glasgow, Scotland           0.437504            0.643681   \n2               NaN                NaN           0.372349            0.448501   \n3               NaN                NaN           0.000000            0.000000   \n4               NaN                NaN           0.109626            0.361287   \n\n          term  \n0     pop rock  \n1  broken beat  \n2       cumbia  \n3  hard trance  \n4      ragtime  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>song_title</th>\n      <th>year</th>\n      <th>release</th>\n      <th>tempo</th>\n      <th>loudness</th>\n      <th>duration</th>\n      <th>song_hotttnesss</th>\n      <th>artist_id</th>\n      <th>artist_name</th>\n      <th>artist_latitude</th>\n      <th>artist_longitude</th>\n      <th>artist_location</th>\n      <th>artist_hotttnesss</th>\n      <th>artist_familiarity</th>\n      <th>term</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SOVFVAK12A8C1350D9</td>\n      <td>Tanssi vaan</td>\n      <td>1995.0</td>\n      <td>Karkuteillä</td>\n      <td>150.778</td>\n      <td>-10.555</td>\n      <td>156.55138</td>\n      <td>0.299877</td>\n      <td>ARMVN3U1187FB3A1EB</td>\n      <td>Karkkiautomaatti</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.356992</td>\n      <td>0.439604</td>\n      <td>pop rock</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SOGTUKN12AB017F4F1</td>\n      <td>No One Could Ever</td>\n      <td>2006.0</td>\n      <td>Butter</td>\n      <td>177.768</td>\n      <td>-2.060</td>\n      <td>138.97098</td>\n      <td>0.617871</td>\n      <td>ARGEKB01187FB50750</td>\n      <td>Hudson Mohawke</td>\n      <td>55.8578</td>\n      <td>-4.24251</td>\n      <td>Glasgow, Scotland</td>\n      <td>0.437504</td>\n      <td>0.643681</td>\n      <td>broken beat</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SOBNYVR12A8C13558C</td>\n      <td>Si Vos Querés</td>\n      <td>2003.0</td>\n      <td>De Culo</td>\n      <td>87.433</td>\n      <td>-4.654</td>\n      <td>145.05751</td>\n      <td>NaN</td>\n      <td>ARNWYLR1187B9B2F9C</td>\n      <td>Yerba Brava</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.372349</td>\n      <td>0.448501</td>\n      <td>cumbia</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SOHSBXH12A8C13B0DF</td>\n      <td>Tangle Of Aspens</td>\n      <td>NaN</td>\n      <td>Rene Ablaze Presents Winter Sessions</td>\n      <td>140.035</td>\n      <td>-7.806</td>\n      <td>514.29832</td>\n      <td>NaN</td>\n      <td>AREQDTE1269FB37231</td>\n      <td>Der Mystic</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>hard trance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SOZVAPQ12A8C13B63C</td>\n      <td>Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...</td>\n      <td>NaN</td>\n      <td>Berwald: Symphonies Nos. 1/2/3/4</td>\n      <td>90.689</td>\n      <td>-21.420</td>\n      <td>816.53506</td>\n      <td>NaN</td>\n      <td>AR2NS5Y1187FB5879D</td>\n      <td>David Montgomery</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.109626</td>\n      <td>0.361287</td>\n      <td>ragtime</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_music_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:11.059206Z",
     "start_time": "2024-05-19T01:28:10.505427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "song_id                    0\nsong_title                 0\nyear                  484270\nrelease                    5\ntempo                      0\nloudness                   0\nduration                   0\nsong_hotttnesss       417782\nartist_id                  0\nartist_name                0\nartist_latitude       641766\nartist_longitude      641766\nartist_location       487546\nartist_hotttnesss         12\nartist_familiarity       185\nterm                    3767\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_music_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:13.725921Z",
     "start_time": "2024-05-19T01:28:13.169005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2677099"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_music_dataset.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: For now I am going to delete all rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:17.833561Z",
     "start_time": "2024-05-19T01:28:16.724382Z"
    }
   },
   "outputs": [],
   "source": [
    "music_dataset = raw_music_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:19.254323Z",
     "start_time": "2024-05-19T01:28:19.234570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "126905"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(music_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Evenly selecing over 1000 songs, and saving them as the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:22.820595Z",
     "start_time": "2024-05-19T01:28:22.769727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126905, 16)\n",
      "(1058, 16)\n"
     ]
    }
   ],
   "source": [
    "print(music_dataset.shape)\n",
    "\n",
    "music_dataset = music_dataset.iloc[::120] # returns dataframe with (1058, 13)\n",
    "\n",
    "print(music_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najeeb: Introducing a new column \"country\" based on Latitude and Longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to load geographical data from a Local GeoJSON file, process it, and subsequently determine which country a given set of Latitudes and Logitudes coordinates falls into. The country names extracted from GeoJSON file are then inserted into a new column in a dataset.\n",
    "\n",
    "- The \"json.load\" function reads the file and convert it into a Python dictionary ('geojson_data').\n",
    "\n",
    "- An Empty dictionary named 'countries' is initiated to store the coordinated data associated with each country.\n",
    "\n",
    "- The script iterates over each feature in the 'features' array of the 'geojson_data'. Each features represents a country.\n",
    "\n",
    "- For each feature, the geometry ('geom') and the administrative name of the country is extracted.\n",
    "\n",
    "- The geometry is then processed with a function 'prep' applied to 'shape(geom)'. This likely involves creating a geometric shape from the geometry data and preparing it for fast spatial queries. The processed geometry is dtored in the 'countries' dictionary with the country name as key.\n",
    "\n",
    "- A function 'get_country' is defined which takes longitudes ('lon') and latitude ('lat') as arguments and creates a ('Point') object from coordinates.\n",
    "\n",
    "- It then iterates  over the 'countries' dictionary and check whether the point is contained within any of the country geometrics using the 'contains' method of the geometry.\n",
    "\n",
    "- if a containing country is found, the function returns the country's name. if no containing country is found, it returns a value 'UNKNOWN_COUNTRY_VALUE'\n",
    "\n",
    "- A new column in the dataset ('msic_dataset') is populated by applying 'get_country' function to each row. In this way the country column is added to music_dataset based on latitude and logitude columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:31.927310Z",
     "start_time": "2024-05-19T01:28:28.636849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fetch and process the geojson data from a local file\n",
    "with open(r'../Data/countries.geojson.json', 'r') as file:\n",
    "    geojson_data = json.load(file)\n",
    "\n",
    "countries = {}\n",
    "for feature in geojson_data[\"features\"]:\n",
    "    geom = feature[\"geometry\"]\n",
    "    country = feature[\"properties\"][\"ADMIN\"]\n",
    "    countries[country] = prep(shape(geom))\n",
    "\n",
    "# Function to get country name from latitude and longitude\n",
    "def get_country(lon, lat):\n",
    "    point = Point(lon, lat)\n",
    "    for country, geom in countries.items():\n",
    "        if geom.contains(point):\n",
    "            return country\n",
    "\n",
    "    return UNKNOWN_COUNTRY_VALUE\n",
    "\n",
    "# Apply the function to create a new 'country' column\n",
    "music_dataset[COUNTRY_COLUMN] = music_dataset.apply(\n",
    "    lambda row: get_country(row[ARTIST_LONGITUDE_COLUMN], \n",
    "    row[ARTIST_LATITUDE_COLUMN]), \n",
    "    axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Deleting redundant columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:35.140195Z",
     "start_time": "2024-05-19T01:28:35.119153Z"
    }
   },
   "outputs": [],
   "source": [
    "music_dataset = music_dataset.drop(\n",
    "    [\n",
    "        ARTIST_LATITUDE_COLUMN,\n",
    "        ARTIST_LONGITUDE_COLUMN,\n",
    "        ARTIST_LOCATION_COLUMN,\n",
    "        SONG_ID_COLUMN,\n",
    "        ARTIST_ID_COLUMN\n",
    "    ], \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Deleting all rows with \"unknown\" as the country value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:44.825230Z",
     "start_time": "2024-05-19T01:28:44.804263Z"
    }
   },
   "outputs": [],
   "source": [
    "music_dataset = music_dataset[music_dataset[COUNTRY_COLUMN] != UNKNOWN_COUNTRY_VALUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:47.206995Z",
     "start_time": "2024-05-19T01:28:47.193955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                          song_title    year  \\\n0                                  No One Could Ever  2006.0   \n1                Don't Save It All For Christmas Day  2004.0   \n2                                         White Lies  2006.0   \n3                           Guess Who I Saw In Paris  1999.0   \n4  No More Birthdays (Phil Spector Folk) / San Fr...  2006.0   \n\n                     release    tempo  loudness   duration  song_hotttnesss  \\\n0                     Butter  177.768    -2.060  138.97098         0.617871   \n1  Merry Christmas With Love  127.397    -9.149  273.08363         0.732281   \n2                   Rocinate   92.103    -9.323  388.80608         0.417314   \n3                   Sugar Me  105.054   -18.484  170.31791         0.368414   \n4             Born To Please   95.658    -6.141  280.45016         0.000000   \n\n       artist_name  artist_hotttnesss  artist_familiarity            term  \\\n0   Hudson Mohawke           0.437504            0.643681     broken beat   \n1       Clay Aiken           0.500596            0.852100        teen pop   \n2      Ester Drang           0.330889            0.525616        shoegaze   \n3  Claudine Longet           0.377489            0.563184  easy listening   \n4       Sound Team           0.368423            0.590111        art rock   \n\n                    country  \n0            United Kingdom  \n1  United States of America  \n2  United States of America  \n3                    France  \n4  United States of America  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_title</th>\n      <th>year</th>\n      <th>release</th>\n      <th>tempo</th>\n      <th>loudness</th>\n      <th>duration</th>\n      <th>song_hotttnesss</th>\n      <th>artist_name</th>\n      <th>artist_hotttnesss</th>\n      <th>artist_familiarity</th>\n      <th>term</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No One Could Ever</td>\n      <td>2006.0</td>\n      <td>Butter</td>\n      <td>177.768</td>\n      <td>-2.060</td>\n      <td>138.97098</td>\n      <td>0.617871</td>\n      <td>Hudson Mohawke</td>\n      <td>0.437504</td>\n      <td>0.643681</td>\n      <td>broken beat</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Don't Save It All For Christmas Day</td>\n      <td>2004.0</td>\n      <td>Merry Christmas With Love</td>\n      <td>127.397</td>\n      <td>-9.149</td>\n      <td>273.08363</td>\n      <td>0.732281</td>\n      <td>Clay Aiken</td>\n      <td>0.500596</td>\n      <td>0.852100</td>\n      <td>teen pop</td>\n      <td>United States of America</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>White Lies</td>\n      <td>2006.0</td>\n      <td>Rocinate</td>\n      <td>92.103</td>\n      <td>-9.323</td>\n      <td>388.80608</td>\n      <td>0.417314</td>\n      <td>Ester Drang</td>\n      <td>0.330889</td>\n      <td>0.525616</td>\n      <td>shoegaze</td>\n      <td>United States of America</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Guess Who I Saw In Paris</td>\n      <td>1999.0</td>\n      <td>Sugar Me</td>\n      <td>105.054</td>\n      <td>-18.484</td>\n      <td>170.31791</td>\n      <td>0.368414</td>\n      <td>Claudine Longet</td>\n      <td>0.377489</td>\n      <td>0.563184</td>\n      <td>easy listening</td>\n      <td>France</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No More Birthdays (Phil Spector Folk) / San Fr...</td>\n      <td>2006.0</td>\n      <td>Born To Please</td>\n      <td>95.658</td>\n      <td>-6.141</td>\n      <td>280.45016</td>\n      <td>0.000000</td>\n      <td>Sound Team</td>\n      <td>0.368423</td>\n      <td>0.590111</td>\n      <td>art rock</td>\n      <td>United States of America</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dataset.reset_index(drop=True, inplace=True)\n",
    "music_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:50.600313Z",
     "start_time": "2024-05-19T01:28:50.580561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1036, 12)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: making sure the final dataset contains 1000 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:54.020927Z",
     "start_time": "2024-05-19T01:28:54.002049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 12)\n"
     ]
    }
   ],
   "source": [
    "music_dataset = music_dataset.iloc[:1000] # returns dataframe with 1000 songs\n",
    "\n",
    "print(music_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Adding decade column to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:28:57.837457Z",
     "start_time": "2024-05-19T01:28:57.827580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                          song_title    year  \\\n0                                  No One Could Ever  2006.0   \n1                Don't Save It All For Christmas Day  2004.0   \n2                                         White Lies  2006.0   \n3                           Guess Who I Saw In Paris  1999.0   \n4  No More Birthdays (Phil Spector Folk) / San Fr...  2006.0   \n\n                     release    tempo  loudness   duration  song_hotttnesss  \\\n0                     Butter  177.768    -2.060  138.97098         0.617871   \n1  Merry Christmas With Love  127.397    -9.149  273.08363         0.732281   \n2                   Rocinate   92.103    -9.323  388.80608         0.417314   \n3                   Sugar Me  105.054   -18.484  170.31791         0.368414   \n4             Born To Please   95.658    -6.141  280.45016         0.000000   \n\n       artist_name  artist_hotttnesss  artist_familiarity            term  \\\n0   Hudson Mohawke           0.437504            0.643681     broken beat   \n1       Clay Aiken           0.500596            0.852100        teen pop   \n2      Ester Drang           0.330889            0.525616        shoegaze   \n3  Claudine Longet           0.377489            0.563184  easy listening   \n4       Sound Team           0.368423            0.590111        art rock   \n\n                    country  decade  \n0            United Kingdom    2000  \n1  United States of America    2000  \n2  United States of America    2000  \n3                    France    1990  \n4  United States of America    2000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_title</th>\n      <th>year</th>\n      <th>release</th>\n      <th>tempo</th>\n      <th>loudness</th>\n      <th>duration</th>\n      <th>song_hotttnesss</th>\n      <th>artist_name</th>\n      <th>artist_hotttnesss</th>\n      <th>artist_familiarity</th>\n      <th>term</th>\n      <th>country</th>\n      <th>decade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No One Could Ever</td>\n      <td>2006.0</td>\n      <td>Butter</td>\n      <td>177.768</td>\n      <td>-2.060</td>\n      <td>138.97098</td>\n      <td>0.617871</td>\n      <td>Hudson Mohawke</td>\n      <td>0.437504</td>\n      <td>0.643681</td>\n      <td>broken beat</td>\n      <td>United Kingdom</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Don't Save It All For Christmas Day</td>\n      <td>2004.0</td>\n      <td>Merry Christmas With Love</td>\n      <td>127.397</td>\n      <td>-9.149</td>\n      <td>273.08363</td>\n      <td>0.732281</td>\n      <td>Clay Aiken</td>\n      <td>0.500596</td>\n      <td>0.852100</td>\n      <td>teen pop</td>\n      <td>United States of America</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>White Lies</td>\n      <td>2006.0</td>\n      <td>Rocinate</td>\n      <td>92.103</td>\n      <td>-9.323</td>\n      <td>388.80608</td>\n      <td>0.417314</td>\n      <td>Ester Drang</td>\n      <td>0.330889</td>\n      <td>0.525616</td>\n      <td>shoegaze</td>\n      <td>United States of America</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Guess Who I Saw In Paris</td>\n      <td>1999.0</td>\n      <td>Sugar Me</td>\n      <td>105.054</td>\n      <td>-18.484</td>\n      <td>170.31791</td>\n      <td>0.368414</td>\n      <td>Claudine Longet</td>\n      <td>0.377489</td>\n      <td>0.563184</td>\n      <td>easy listening</td>\n      <td>France</td>\n      <td>1990</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No More Birthdays (Phil Spector Folk) / San Fr...</td>\n      <td>2006.0</td>\n      <td>Born To Please</td>\n      <td>95.658</td>\n      <td>-6.141</td>\n      <td>280.45016</td>\n      <td>0.000000</td>\n      <td>Sound Team</td>\n      <td>0.368423</td>\n      <td>0.590111</td>\n      <td>art rock</td>\n      <td>United States of America</td>\n      <td>2000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dataset = music_dataset.assign(decade=lambda row: (row[YEAR_COLUMN].astype(int) // 10) * 10)\n",
    "music_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:01.004104Z",
     "start_time": "2024-05-19T01:29:00.996957Z"
    }
   },
   "outputs": [],
   "source": [
    "min_decade = music_dataset[DECADE_COLUMN].min()\n",
    "max_decade = music_dataset[DECADE_COLUMN].max()\n",
    "decade_array = np.arange(min_decade, max_decade + 10, 10, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Saving music_dataset as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:02.337554Z",
     "start_time": "2024-05-19T01:29:02.280795Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(MUSIC_DATA_FOLDER_PATH):\n",
    "    os.mkdir(MUSIC_DATA_FOLDER_PATH)\n",
    "\n",
    "music_dataset.to_csv(f\"{MUSIC_DATA_FOLDER_PATH}/music_dataset.csv\", mode='w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: I will normalize the numeric columns using min max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:05.548227Z",
     "start_time": "2024-05-19T01:29:05.531995Z"
    }
   },
   "outputs": [],
   "source": [
    "def min_max_normalize_column(df, column_name):\n",
    "    min_val = df[column_name].min()\n",
    "    max_val = df[column_name].max()\n",
    "    \n",
    "    if min_val == max_val:\n",
    "        raise ValueError(\"Cannot normalize column when all values are the same.\")\n",
    "    \n",
    "    df[column_name] = (df[column_name] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:06.458735Z",
     "start_time": "2024-05-19T01:29:06.449987Z"
    }
   },
   "outputs": [],
   "source": [
    "normalized_music_dataset = music_dataset.copy()\n",
    "\n",
    "for numeric_column in NUMERIC_COLUMNS_LIST:\n",
    "    min_max_normalize_column(normalized_music_dataset, numeric_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:07.327557Z",
     "start_time": "2024-05-19T01:29:07.312581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                          song_title      year  \\\n0                                  No One Could Ever  0.927273   \n1                Don't Save It All For Christmas Day  0.890909   \n2                                         White Lies  0.927273   \n3                           Guess Who I Saw In Paris  0.800000   \n4  No More Birthdays (Phil Spector Folk) / San Fr...  0.927273   \n\n                     release     tempo  loudness  duration  song_hotttnesss  \\\n0                     Butter  0.716171  0.961028  0.100247         0.620488   \n1  Merry Christmas With Love  0.513242  0.763265  0.203325         0.735383   \n2                   Rocinate  0.371054  0.758411  0.292268         0.419082   \n3                   Sugar Me  0.423229  0.502846  0.124340         0.369974   \n4             Born To Please  0.385376  0.847180  0.208987         0.000000   \n\n       artist_name  artist_hotttnesss  artist_familiarity            term  \\\n0   Hudson Mohawke           0.511917            0.671199     broken beat   \n1       Clay Aiken           0.585741            0.906486        teen pop   \n2      Ester Drang           0.387169            0.537915        shoegaze   \n3  Claudine Longet           0.441695            0.580325  easy listening   \n4       Sound Team           0.431087            0.610724        art rock   \n\n                    country    decade  \n0            United Kingdom  0.833333  \n1  United States of America  0.833333  \n2  United States of America  0.833333  \n3                    France  0.666667  \n4  United States of America  0.833333  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_title</th>\n      <th>year</th>\n      <th>release</th>\n      <th>tempo</th>\n      <th>loudness</th>\n      <th>duration</th>\n      <th>song_hotttnesss</th>\n      <th>artist_name</th>\n      <th>artist_hotttnesss</th>\n      <th>artist_familiarity</th>\n      <th>term</th>\n      <th>country</th>\n      <th>decade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No One Could Ever</td>\n      <td>0.927273</td>\n      <td>Butter</td>\n      <td>0.716171</td>\n      <td>0.961028</td>\n      <td>0.100247</td>\n      <td>0.620488</td>\n      <td>Hudson Mohawke</td>\n      <td>0.511917</td>\n      <td>0.671199</td>\n      <td>broken beat</td>\n      <td>United Kingdom</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Don't Save It All For Christmas Day</td>\n      <td>0.890909</td>\n      <td>Merry Christmas With Love</td>\n      <td>0.513242</td>\n      <td>0.763265</td>\n      <td>0.203325</td>\n      <td>0.735383</td>\n      <td>Clay Aiken</td>\n      <td>0.585741</td>\n      <td>0.906486</td>\n      <td>teen pop</td>\n      <td>United States of America</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>White Lies</td>\n      <td>0.927273</td>\n      <td>Rocinate</td>\n      <td>0.371054</td>\n      <td>0.758411</td>\n      <td>0.292268</td>\n      <td>0.419082</td>\n      <td>Ester Drang</td>\n      <td>0.387169</td>\n      <td>0.537915</td>\n      <td>shoegaze</td>\n      <td>United States of America</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Guess Who I Saw In Paris</td>\n      <td>0.800000</td>\n      <td>Sugar Me</td>\n      <td>0.423229</td>\n      <td>0.502846</td>\n      <td>0.124340</td>\n      <td>0.369974</td>\n      <td>Claudine Longet</td>\n      <td>0.441695</td>\n      <td>0.580325</td>\n      <td>easy listening</td>\n      <td>France</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No More Birthdays (Phil Spector Folk) / San Fr...</td>\n      <td>0.927273</td>\n      <td>Born To Please</td>\n      <td>0.385376</td>\n      <td>0.847180</td>\n      <td>0.208987</td>\n      <td>0.000000</td>\n      <td>Sound Team</td>\n      <td>0.431087</td>\n      <td>0.610724</td>\n      <td>art rock</td>\n      <td>United States of America</td>\n      <td>0.833333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_music_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Now I am going to create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:09.123823Z",
     "start_time": "2024-05-19T01:29:09.115098Z"
    }
   },
   "outputs": [],
   "source": [
    "music_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:10.648474Z",
     "start_time": "2024-05-19T01:29:10.583903Z"
    }
   },
   "outputs": [],
   "source": [
    "for current_index, current_row in normalized_music_dataset.iterrows():\n",
    "    node_data_dict = {}\n",
    "\n",
    "    for current_column in NUMERIC_COLUMNS_LIST:\n",
    "        node_data_dict[current_column] = current_row[current_column]\n",
    "\n",
    "    music_graph.add_node(current_index, **node_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:11.335992Z",
     "start_time": "2024-05-19T01:29:11.312635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shartil: adding empty nodes for the decades, which function as main nodes\n",
    "# i.e., all the songs from 1950 will be connected to the 1950 node.\n",
    "# This will save complex logic of connecting all the songs from the decade, and ensuring that the resulted graph will be less complicated.\n",
    "for current_decade in decade_array:\n",
    "    node_name = get_attribute_node_name(DECADE_COLUMN, current_decade)\n",
    "    music_graph.add_node(node_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: for now, the graph only has decade nodes & song nodes that contain their matching ID in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:12.827745Z",
     "start_time": "2024-05-19T01:29:12.712398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 1007 nodes and 1000 edges\n"
     ]
    }
   ],
   "source": [
    "for index, row in music_dataset.iterrows():\n",
    "    current_decade = row[DECADE_COLUMN]\n",
    "    node_name = get_attribute_node_name(DECADE_COLUMN, current_decade)\n",
    "    music_graph.add_edge(node_name, index)\n",
    "\n",
    "print(music_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:13.624529Z",
     "start_time": "2024-05-19T01:29:13.616220Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_songs_by_criteria(music_graph, given_criteria):\n",
    "    selected_songs = [ song for song in music_graph[given_criteria].keys()]\n",
    "    return selected_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:14.576427Z",
     "start_time": "2024-05-19T01:29:14.567883Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_length_and_items(given_list, amont_of_items = 50):\n",
    "    print(len(given_list))\n",
    "    print(given_list[:amont_of_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T01:29:15.255951Z",
     "start_time": "2024-05-19T01:29:15.248123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "[3, 12, 18, 23, 24, 28, 34, 35, 53, 54, 55, 58, 70, 71, 75, 77, 80, 92, 93, 94, 98, 101, 102, 104, 109, 112, 115, 117, 121, 126, 131, 138, 143, 145, 158, 159, 162, 166, 167, 168, 176, 178, 180, 186, 189, 191, 193, 198, 199, 202]\n"
     ]
    }
   ],
   "source": [
    "decade_input = 1990\n",
    "node_name = get_attribute_node_name(DECADE_COLUMN, decade_input)\n",
    "\n",
    "decade_songs = get_songs_by_criteria(music_graph, node_name)\n",
    "print_length_and_items(decade_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: this code no longer works, since the knowledge graph doesnt contain country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_input = \"Sweden\"\n",
    "\n",
    "# country_songs = get_songs_by_criteria(music_graph, country_input)\n",
    "# print_length_and_items(country_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shartil: Now let's get the intersection of the lists<br>\n",
    "This code was taken from this [StackOverflow answer](https://stackoverflow.com/a/3697438/9609586)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The songs from Sweden that were released in 1990:\")\n",
    "\n",
    "# result_list = list(set(decade_songs) & set(country_songs))\n",
    "# print_length_and_items(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Riaz: Node Embeding using node2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "Computing transition probabilities:   0%|          | 0/1007 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff3197d124d24326a3af6abb3c47736b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:09<00:00,  5.51it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:09<00:00,  5.50it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [00:09<00:00,  5.46it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:09<00:00,  5.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
    "node2vec = Node2Vec(music_graph, dimensions=64, walk_length=10, num_walks=200, workers=4)  # Use temp_folder for big graphs\n",
    "\n",
    "# Embed nodes\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:41:21.241500Z",
     "start_time": "2024-05-19T01:40:06.593448Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving embedding and model into models folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "\n",
    "# Save embeddings for later use\n",
    "model.wv.save_word2vec_format(f\"{MODELS_FOLDER_PATH}/embedding\")\n",
    "\n",
    "# Save model for later use\n",
    "model.save(f\"{MODELS_FOLDER_PATH}/node2vec_model\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:41:27.075674Z",
     "start_time": "2024-05-19T01:41:26.973112Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Riaz: Nodes clustering based on embedding using K-Means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (1007, 64)\n",
      "Vectors : [[-8.87519047e-02  4.64707240e-02  1.01184301e-01  4.76024926e-01\n",
      "  -2.08615005e-01 -2.13695958e-01  3.62863749e-01  6.45037964e-02\n",
      "  -1.05757378e-01 -1.23130515e-01  6.17349148e-01 -8.56697261e-02\n",
      "   5.61661273e-03 -2.57294148e-01 -4.34916578e-02  2.29714572e-01\n",
      "   7.66308606e-02 -8.14373568e-02 -1.64118066e-01 -1.04754325e-02\n",
      "   2.74835616e-01  2.65286207e-01  9.02275220e-02 -4.18187320e-01\n",
      "  -2.69567192e-01  9.51370001e-02 -1.26770392e-01  2.07653016e-01\n",
      "  -1.80968121e-01  1.19017452e-01 -6.30519390e-02 -4.76274863e-02\n",
      "   3.28287899e-01 -5.73682368e-01 -4.89366442e-01  3.90114635e-01\n",
      "   3.25769693e-01  2.50507772e-01 -1.71384722e-01 -2.49990404e-01\n",
      "  -5.56424797e-01  4.21053588e-01 -1.83949932e-01  4.46699202e-01\n",
      "   2.31308848e-01 -1.54556632e-01 -1.44896820e-01  8.38391781e-02\n",
      "   1.07053630e-01  9.62468460e-02 -5.36897898e-01  2.80958742e-01\n",
      "  -2.29705885e-01  2.92848140e-01  2.83302665e-01 -2.94188976e-01\n",
      "   1.22754931e-01 -4.36842859e-01 -4.00900185e-01  3.56736183e-01\n",
      "   5.28163835e-02 -8.84623080e-02 -2.93572485e-01 -3.47029835e-01]\n",
      " [-1.68963417e-01 -9.73678107e-05  3.60944182e-01  5.83047986e-01\n",
      "  -8.11455965e-01 -2.71187067e-01  7.36441970e-01  2.20425427e-01\n",
      "   1.20450318e-01 -1.77012518e-01  2.25365490e-01 -1.97366640e-01\n",
      "  -1.75868899e-01 -1.85133934e-01 -3.67206216e-01 -1.18014067e-01\n",
      "  -5.87044418e-01 -4.10264544e-02  4.68196720e-02  3.89488786e-01\n",
      "  -9.64569114e-03  2.83449620e-01  2.20270962e-01 -5.36839724e-01\n",
      "   4.14424807e-01  6.70446873e-01 -9.11689252e-02  8.17647502e-02\n",
      "   2.87761148e-02 -6.11997247e-01 -2.78034002e-01  1.00124650e-01\n",
      "  -1.85983539e-01 -4.53275681e-01  5.73586188e-02 -5.24037331e-02\n",
      "  -4.20527428e-01 -8.41000080e-02  3.94484162e-01  4.07720357e-01\n",
      "   1.58884481e-01 -2.73854554e-01 -2.38377839e-01  9.88969356e-02\n",
      "   9.97901410e-02  3.64715792e-02 -2.79380351e-01 -4.63707224e-02\n",
      "  -1.96557537e-01 -2.38439322e-01 -1.13533884e-01  8.33078444e-01\n",
      "   2.63436109e-01  5.69379270e-01 -3.19591403e-01 -7.26435408e-02\n",
      "   1.82816178e-01 -1.92452520e-01  1.04606420e-01 -3.76621485e-01\n",
      "   6.48509115e-02  9.21462923e-02 -2.36712247e-01 -9.86707509e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the embeddings and their labels\n",
    "embeddings = model.wv\n",
    "labels = list(embeddings.index_to_key)\n",
    "X = np.array([embeddings[label] for label in labels])\n",
    "\n",
    "print('Shape of X: ',X.shape)\n",
    "print('Vectors :', X[:2])\n",
    "\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(X)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "cluster_nodes = {}\n",
    "\n",
    "# Print the clusters\n",
    "for i, label in enumerate(labels):\n",
    "    if clusters[i] in cluster_nodes:\n",
    "        cluster_nodes[clusters[i]] = cluster_nodes[clusters[i]] + [label]\n",
    "    else:\n",
    "        cluster_nodes[clusters[i]] = [label]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:42:57.401035Z",
     "start_time": "2024-05-19T01:42:57.321353Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Displaying numbers of nodes in each cluster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cluster: 0. Nodes: ['decade 2000', '801', '707', '110', '543', '244', '84', '532', '415', '526', '197', '219', '10', '489', '550', '394', '144', '419', '521', '490', '957', '715', '214', '122', '906', '500', '752', '847', '552', '285', '310', '432', '248', '228', '798', '91', '497', '229', '27', '448', '966', '969', '16', '799', '59', '152', '754', '896', '910', '358', '946', '286', '591', '596', '323', '66', '320', '477', '653', '697', '598', '779', '991', '895', '31', '578', '581', '507', '743', '366', '577', '692', '442', '820', '538', '113', '250', '805', '243', '316', '129', '668', '302', '11', '629', '425', '137', '268', '825', '160', '386', '758', '384', '755', '597', '787', '407', '73', '51', '263', '298', '959', '452', '599', '986', '525', '975', '179', '82', '704', '900', '462', '463', '293', '999', '221', '322', '161', '38', '150', '314', '834', '57', '210', '331', '768', '499', '730', '674', '627', '222', '155', '62', '522', '968', '992', '465', '875', '340', '595', '897', '149', '659', '830', '132', '43', '148', '207', '749', '796', '315', '119', '171', '870', '933', '955', '679', '611', '844', '502', '213', '773', '118', '354', '732', '588', '2', '965', '567', '130', '377', '246', '987', '446', '146', '514', '76', '67', '944', '970', '892', '496', '797', '114', '980', '914', '974', '858', '537', '781', '534', '339', '68', '548', '816', '780', '405', '233', '1', '265', '518', '362', '25', '523', '786', '165', '634', '313', '881', '482', '656', '273', '592', '291', '602', '842', '547', '308', '838', '190', '125', '849', '612', '686', '257', '296', '655', '236', '72', '491', '630', '408', '751', '546', '238', '939', '513', '671', '545', '164', '610', '266', '317', '636', '385', '455', '334', '652', '746', '812', '483', '824', '706', '5', '640', '4', '835', '469', '759', '593', '703', '69', '240', '859', '616', '639', '284', '682', '391', '175', '818', '658', '889', '573', '560', '103', '711', '74', '869', '458', '183', '353', '564', '833', '644', '622', '708', '566', '134', '139', '582', '63', '880', '857', '788', '395', '637', '232', '350', '557', '29', '701', '873', '184', '0', '964', '218', '673', '589', '565', '116', '800', '64', '868', '404', '808', '887', '580'] \n",
      "\n",
      " Cluster: 2. Nodes: ['decade 1990', 'decade 1960', 'decade 2010', 'decade 1950', '441', '952', '923', '648', '579', '234', '211', '481', '402', '879', '156', '367', '527', '724', '398', '937', '517', '878', '14', '904', '217', '342', '295', '437', '81', '480', '925', '34', '766', '255', '535', '617', '278', '321', '872', '90', '783', '750', '791', '337', '471', '198', '189', '806', '212', '839', '646', '666', '230', '790', '919', '843', '680', '951', '614', '803', '223', '325', '972', '554', '982', '365', '166', '231', '433', '683', '712', '485', '867', '551', '615', '264', '453', '777', '434', '319', '109', '71', '688', '115', '840', '413', '60', '158', '80', '922', '943', '763', '620', '454', '468', '53', '58', '417', '390', '20', '945', '473', '332', '631', '509', '23', '853', '985', '571', '633', '860', '306', '270', '409', '447', '427', '934', '55', '24', '575', '748', '531', '929', '143', '347', '104', '376', '997', '35', '976', '776', '921', '300', '950', '370', '871', '775', '424', '93', '168', '374', '729', '936', '520', '445', '984', '117', '542', '112', '540', '70', '927', '624', '495', '891', '180', '126', '98', '461', '330', '719', '731', '357', '983', '475', '283', '813', '827', '474', '533', '131', '472', '675', '420', '501', '677', '559', '159', '693', '760', '186', '563', '145', '841', '662', '665', '851', '960', '411', '466', '905', '282', '292', '138', '203', '956', '888', '235', '178', '819', '101', '416', '884', '18', '202', '877', '479', '909', '294', '911', '978', '176', '684', '539', '714', '753', '260', '549', '804', '307', '414', '37', '765', '770', '661', '54', '977', '199', '600', '762', '102', '669', '460', '720', '757', '369', '121', '435', '305', '94', '628', '205', '12', '444', '795', '215', '267', '49', '823', '225', '364', '288', '28', '784', '988', '761', '863', '664', '277', '901', '638', '717', '3', '678', '75', '993', '771', '191', '519', '193', '276', '601', '953', '167', '865', '918', '676', '876', '942', '318', '996', '346', '846', '418', '92', '695', '583', '556', '778', '696', '647', '440', '626', '77', '162', '917', '281', '710', '356', '826', '249', '352', '831', '606', '397', '848', '363', '304', '672'] \n",
      "\n",
      " Cluster: 1. Nodes: ['decade 1980', '745', '894', '42', '504', '476', '375', '187', '65', '529', '195', '200', '739', '327', '528', '590', '725', '747', '486', '107', '782', '737', '971', '487', '742', '687', '510', '585', '275', '449', '605', '389', '722', '245', '954', '700', '106', '309', '254', '256', '410', '723', '372', '422', '864', '279', '850', '608', '78', '450', '650', '52', '793', '105', '371', '607', '338', '705', '45', '123', '785', '962', '702', '726', '252', '9', '439', '716', '663', '163', '981', '718', '188', '181', '990', '21', '44', '822'] \n",
      "\n",
      " Cluster: 3. Nodes: ['decade 1970', '83', '625', '699', '258', '736', '623', '379', '280', '470', '41', '47', '289', '135', '201', '271', '574', '713', '259', '451', '312', '958', '935', '505', '512', '85', '242', '516', '127', '815', '423', '247', '569', '568', '609', '821', '654', '348', '493', '924', '237', '87', '147', '431', '396', '194', '886', '8', '734', '845', '948', '989', '632', '667', '494', '182', '380', '862', '587'] \n",
      "\n",
      " Cluster: 4. Nodes: ['124', '484', '930', '261', '817', '837', '464', '530', '721', '899', '272', '48', '7', '26', '928', '926', '829', '811', '794', '584', '562', '908', '856', '174', '19', '789', '32', '311', '558', '241', '641', '86', '326', '170', '456', '882', '890', '570', '157', '769', '643', '56', '100', '618', '401', '883', '344', '738', '151', '428', '931', '79', '603', '498', '932', '524', '586', '744', '177', '297', '561', '216', '206', '303', '698', '902', '832', '142', '335', '421', '555', '709', '172', '855', '361', '274', '400', '128', '621', '459', '544', '511', '382', '814', '874', '120', '95', '506', '467', '741', '613', '670', '756', '492', '961', '154', '224', '345', '368', '649', '324', '429', '204', '995', '963', '185', '912', '689', '136', '940', '947', '541', '13', '89', '916', '196', '553', '133', '40', '660', '333', '406', '39', '488', '387', '99', '253', '251', '209', '349', '343', '645', '336', '594', '740', '681', '355', '341', '767', '351', '373', '861', '208', '359', '503', '802', '88', '938', '651', '457', '727', '866', '998', '915', '381', '412', '536', '619', '290', '973', '690', '22', '691', '949', '764', '299', '169', '97', '735', '287', '907', '733', '774', '979', '941', '635', '33', '192', '604', '443', '403', '30', '994', '508', '657', '836', '642', '572', '438', '329', '478', '140', '6', '898', '301', '426', '920', '220', '685', '383', '885', '46', '15', '378', '17', '810', '913', '392', '809', '828', '50', '576', '153', '227', '226', '262', '360', '111', '399', '792', '108', '141', '807', '269', '61', '173', '328', '436', '388', '854', '967', '893', '239', '772', '36', '515', '96', '430', '728', '393', '903', '852', '694'] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in cluster_nodes:\n",
    "    print(f\" Cluster: {i}. Nodes: {cluster_nodes[i]} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T01:43:06.702559Z",
     "start_time": "2024-05-19T01:43:06.689300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a5cfde8991b0f64e8bcd60a397bea8dc10ed042aefe1441fd3daa2ae2091421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
